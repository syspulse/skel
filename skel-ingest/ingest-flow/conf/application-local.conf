
#akka.stream.alpakka.dynamodb {
alpakka.elastic {
}

akka {
  quartz {
    threadPool {
        threadCount = 1
        threadPriority = 5
        daemonThreads = true
    }
    defaultTimezone = UTC
   
    schedules {
      EverySecond {
        description = "A cron job that fires off every 30 seconds"
        expression = "*/1 * * * * ?"        
      }
      Every30Seconds {
        description = "A cron job that fires off every 30 seconds"
        expression = "*/30 * * ? * *"
        calendar = "OnlyBusinessHours"
      }
    }
  }
}

akka.http.server.remote-address-attribute = on

mysql {
  dataSourceClassName=com.mysql.cj.jdbc.MysqlDataSource
  dataSource.url="jdbc:mysql://localhost:3306/ingest_db"
  dataSource.user=ingest_user
  dataSource.password=ingest_pass
  connectionTimeout=30000
  idleTimeout=30000
  minimumIdle=5
  maximumPoolSize=20
  poolName=DB-Pool
  maxLifetime=2000000
}

postgres {
  dataSourceClassName=org.postgresql.ds.PGSimpleDataSource
  dataSource.url="jdbc:postgresql://localhost:5432/ingest_db"  
  dataSource.user=ingest_user
  dataSource.password=ingest_pass
  connectionTimeout=30000
  idleTimeout=30000
  minimumIdle=5
  maximumPoolSize=20
  poolName=DB-Pool
  maxLifetime=2000000
}

akka.kafka.producer {
  # Duration to wait for `KafkaProducer.close` to finish.
  close-timeout = 10s

  # Call `KafkaProducer.close` when the stream is shutdown. This is important to override to false
  # when the producer instance is shared across multiple producer stages.
  close-on-producer-stop = true
}

# akka{
#   http {
#       server {
#         idle-timeout = 10 seconds
#         websocket{
#           periodic-keep-alive-mode = ping
#           periodic-keep-alive-max-idle = 5 seconds
#         }
#       }
#       client {
#         idle-timeout = 3 seconds
#         websocket{
#           periodic-keep-alive-mode = ping
#           periodic-keep-alive-max-idle = 5 seconds
#         }
#       }
#   }
# }

akka.loglevel = "DEBUG"

http {
   port = 8081
}
